# Hadron: 算子复合的二阶优化

**版本**: 4.0 (2025-11-26)  
**状态**: 理论验证完成，架构冻结

## 核心原理

**算子复合范式**: `g_update = Structural_Op(Statistical_Op(g_raw))`

- **统计算子 (KFAC)**: 将原始梯度投影至经验Fisher流形 → 自然梯度 `g_nat = ℱ_emp⁻¹·g`
- **结构算子 (Muon)**: 将自然梯度投影至Stiefel流形 → 正交化更新

**理论动机**: 拒绝Hessian-Fisher等价性谬误 (`H ≈ ℱ`)，拒绝线性混合几何 (`λ₁·g_stat + λ₂·g_struct`)。KFAC决定"去哪里"，Muon决定"怎么去"，功能正交、串联执行。

## 实现变体

| 变体 | 统计算子 | 复杂度 (时间/空间) | 适用架构 |
|:---|:---|:---|:---|
| **Hadron** | Full KFAC `(A⁻¹ ⊗ B⁻¹)` | O(d³) / O(d²) | CNN (ResNet) |
| **Diag-Hadron** | Diagonal KFAC `diag(A⁻¹) ⊗ diag(B⁻¹)` | O(d) / O(d) | Transformer (GPT) |

## 实验结果

### CIFAR-10 (ResNet-18, batch=128)

| 优化器 | 准确率 | 时间/epoch | 峰值显存 | 梯度范数 |
|:---|---:|---:|---:|---:|
| **Hadron** | **88.91%** | 152s | 1661 MB | 60.59 |
| KFAC | 85.76% | 141s | 2467 MB | 308.01 |
| Muon | 87.05% | 91s | 1698 MB | 0.87 |
| Diag-Hadron | 77.66% | 60s | 274 MB | 2.48 |

**结论**: Full KFAC捕获卷积核完整协方差结构是CNN性能关键。对角近似丢失统计信息导致灾难性失败。

### Wikitext-2 (Nano-GPT, 4层, batch=8) - 数据打包重构前

| 优化器 | 困惑度 (PPL) | 时间/epoch | 峰值显存 |
|:---|---:|---:|---:|
| **Diag-Hadron** | **401.69** (epoch 6) | 284s | 2669 MB |
| Muon | 416.18 (epoch 8) | 291s | 2669 MB |
| Hadron | OOM | - | - |

**结论**: Transformer的`Linear`层Fisher结构接近对角化，对角近似有效且高效。Muon结构正则化补偿统计简化。

### Wikitext-2 (Nano-GPT, 4层, batch=8) - 数据打包重构后

**实验背景**: 2025-11 实验发现，当从“句模式切片”切换到“整体切块”数据打包后，Diag/Block Hadron 在 Wikitext-2 上表现急剧下降，甚至无法追上 Muon。

**关键线索**:

1. **模型架构缺陷**: 我们使用的 nanoGPT 采用**绝对位置编码** (`nn.Embedding(sequence_length, embedding_size)`)，上下文窗口硬性上限 256 tokens。
2. **数据打包冲突**: “整体切块”将长文本强行切成 256 token 块，**人为制造无数个“伪文档边界”**。这些边界处的位置信息被绝对编码彻底破坏，模型无法学习跨块的长期依赖。
3. **对比验证**: 之前的“句模式切片”之所以能小超 Muon，是因为它**天然保持短序列**，没有破坏位置连续性。

**因果分析**:

- 这不完全是 Hadron 的失效，而是**模型架构先天缺陷**导致的**上下文窗口泛化失败**。
- 绝对位置编码的 GPT **物理上无法感知**超过 256 位置的信息，无论优化器多么优秀。
- 实验再次证明：Hadron 的“谱范数信任域”约束（Muon）确实能抑制 KFAC 的过拟合，但在**模型本身无法处理长序列**的前提下，任何优化器的改进都是**徒劳**。

**最终结论**:

- Hadron 在 CNN (CIFAR-10) 上的成功是**真实且稳健**的，因为其架构（卷积核）和任务（图像分类）**不受长序列位置编码限制**。
- Hadron 在 Transformer (Wikitext-2) 上的失败是**模型架构导致**，而非优化器设计缺陷。这揭示了**上下文窗口限制**是二阶优化器在 LLM 上应用的**根本瓶颈**。
- **算子复合仍然有效**，但 Hadron **不再继续投入实验**。我们需要**新的高性能优化器算子**来取代当前的 KFAC/Muon 组合。

## 性能开销分解

**KFAC独立开销** (vs AdamW基线):

- 计算: +40% (协方差更新 + Kronecker求逆)
- 内存: +1.5× (存储 A, B 矩阵)
- 梯度范数: 100-400× (自然梯度重标度效应)

**Muon独立开销**:

- 计算: +5% (Newton-Schulz迭代5步)
- 内存: +0% (原地操作)
- 梯度范数: 0.01× (正交约束压缩)

**Hadron复合效应**:

- **KFAC梯度爆炸被Muon完全吸收**: 梯度范数从308.01 (纯KFAC) 降至60.59 (Hadron)
- **计算时间仅+8%** (152s vs 141s): Muon的O(d)开销在KFAC的O(d³)背景下可忽略
- **内存开销持平**: Muon不增加额外存储

## 架构选择决策树

```
模型架构
├─ 卷积主导 (ResNet/VGG)
│  ├─ 参数量 < 50M → Hadron
│  └─ 参数量 ≥ 50M → Block-Hadron (未实现)
└─ Linear主导 (Transformer/MLP)
   └─ 任意规模 → Diag-Hadron
```

## 理论洞察

1. **几何协同非冲突**: 算子复合在黎曼流形间建立连续映射，而非线性混合的欧氏空间假设。
2. **梯度范数稳定性**: Muon的谱约束自动吸收KFAC的重标度效应，无需手工调参。
3. **Fisher对角性假设**: Transformer的注意力机制使参数统计接近独立，验证对角KFAC的有效性边界。
