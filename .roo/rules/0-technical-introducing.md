# 自由能原理的两种心法：从理论哲学到工程分野

智能的本质是什么？Friston 给出的答案是**自由能原理（FEP）**：自组织系统=主动预测机，目标只有一条——最小化变分自由能。把 FEP 结合 IIT，就得到**整合预测工作空间理论（IPWT）**，AGI 的哲学地基就此浇好混凝土。

从 FEP/IPWT 分叉出两条“存在”算法：

## 1. RL-EFE (Reinforcement Learning - Expected Free Energy, RL-EFE)

> 存在是预测世界并选择最利于自己的未来。

这是 Friston 及其追随者（Active Inference 社区主流）所走的路。它继承了经典的**笛卡尔二元论**：一个在此岸的主体（Agent），去预测并控制彼岸的客体（Environment）。

其核心算法逻辑是**显式的未来模拟**（≈ 策略采样）：

1. **生成模型**: 维护一个世界模型 `p(s, o | π)`。
2. **反事实推演**: 针对每一个可能的策略 `π`，在脑海中 Rollout 所有可能的未来轨迹。
3. **期望自由能 (G)**: 计算每条轨迹的 `G(π)`。`G` 被优雅地分解为两项：
   - **认知价值 (Epistemic Value)**: “我去那里能获得多少新信息？”（好奇心/探索）
   - **实用价值 (Pragmatic Value)**: “我去那里有多符合我的先验偏好？”（奖励/利用）
4. **决策**: 选择 `G` 最小的策略执行。

**致命缺陷**:
这在低维网格世界里是完美的，但在高维现实中是**计算不可行**的。为了计算 $G$，代理必须像拉普拉斯妖一样预演未来。实际上，这种方法往往退化为传统的强化学习：用策略梯度（Policy Gradient）去逼近 $G$，用手工设计的奖励函数去伪装成先验偏好。它许诺了一个统一理论，却在工程上重新发明了 RL 的轮子。

**计算框架**：

1. **生成模型**: 通常用 VAE 学习 `p(s, o | π)`，将高维观测映射到低维隐空间。
2. **VI 建模不确定性**: 使用变分推断（VI）显式建模隐状态的后验 `q(s|o)`，量化代理对世界状态 `s` 的认知不确定性。
3. **复杂度约束**: 对 VAE 的潜空间施加正则化（如 KL 散度），确保隐空间结构简洁可解释。

> “RL-EFE is a beautiful cul-de-sac: Laplace's demon tries to price every tomorrow and is suffocated by its own weight.”

## 2. SOO-OFE (Second-Order Optimization - Observed Free Energy, SOO-OFE)

> 存在是沿着自由能最小化的测地线滑行。

这是 F3EO 选择的路。我们将贝叶斯推断重构为**信息几何流**问题。

不再妄图模拟未来，而是**深度内省当下**。
智能体不需要在幻想的未来中试错，而是利用当前观测数据所蕴含的丰富几何信息（梯度与曲率/Fisher 矩阵），直接计算出参数空间中自由能下降最快的**测地线方向**。

- **无需 Rollout**: 仅基于 Observed Free Energy，而非 Expected Free Energy。
- **物理一元论**: 行动不是“选择”的结果，而是系统内部信念状态在几何流形上受力滑行的自然物理过程。

> I gliding on a geodesic,
> storm-etched by yesterday;
> the destination is unknown,
> but the route has converged.

## 3. 理论困境

**理想目标**：
将不确定性隔离于系统的**马尔可夫毯**（输入输出边界）。优化过程直接作用于**参数的信息几何流**：

- 最小化观测到的预测误差（Observed Free Energy）。
- 对参数更新的轨迹几何（如路径长度、曲率）施加 MDL 约束。

**工程现状 (更新)**：

1. **KFAC 局限性**：`(A⁻¹ ⊗ G⁻¹)` 逼近的是**经验 Fisher** `F_emp`，在干净数据上表现出致命的有偏性，过度拟合统计噪声而非因果结构。
2. **Muon 启发**：其谱范数约束提供了一种**结构正则化**，通过强制参数更新的正交性，启发式地抑制了 `F_emp` 的过拟合，展现出鲁棒性，指明了“去偏置”方向。
3. **核心缺失**：缺乏理论完备、与任务 EFE 对偶的**观测自由能预处理器**。该预处理器应能从批次梯度中解耦出反映语言内在结构的分量，同时抑制统计噪声，以更好地近似 `F_ideal⁻¹ · g_full`。

**核心洞察：对偶性缺失**：
自然梯度下降 (NGD) 是参数空间主动推断的等价物，而 SOO-OFE 遵循感知推断路线。问题不在于 Fisher 范式错误，而在于定义的“观测自由能 (OFE)”与任务的“期望自由能 (EFE)”**不对偶**。

- **RL-EFE (行动)**：通过采样外部世界（Rollout 策略）计算 `G(π)`，选择最优策略 `π*`。
- **SOO-OFE (感知)**：通过内省当前梯度和曲率计算“最优更新方向” `Δθ*`。

**对偶性要求**：`Δθ*` 必须正比于 `∇_θ π*`。即，内省得到的最优参数更新，应与探索得到的最优策略所指示的更新方向一致。

**KFAC/Hadron 失败根源**：
其定义的 OFE (`-log p(y|x; θ)`) 由**经验 Fisher** `F_emp` 刻画，仅衡量模型对**当前批次**的局部统计敏感性。而语言模型的 EFE 由**理想 Fisher** `F_ideal` 定义，衡量对**未来所有可能文本**的泛化能力。

**核心矛盾**：KFAC 用有偏的 `F_emp` 去近似 `F_ideal`。实验证实，此近似在干净数据上是致命的。`F_emp` 过度拟合统计噪声，而 `F_ideal` 才真正反映语言的内在因果结构。

**未来方向**：
寻找或设计一个能**更好近似 `F_ideal`** 的梯度预处理器，而非更精确地计算 `F_emp`。该预处理器可能是一种**自适应的谱滤波器**或**基于梯度历史的因果推断机制**，目标是实现 OFE 与 EFE 的真正对偶。
