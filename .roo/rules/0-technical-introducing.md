# 自由能原理的两种心法：从理论哲学到工程分野

智能的本质是什么？弗里斯顿给出的答案是**自由能原理（FEP）**：自组织系统=主动预测机，目标只有一条——最小化变分自由能。把 FEP 结合 IIT，就得到**整合预测工作空间理论（IPWT）**，AGI 的哲学地基就此浇好混凝土。

从 FEP/IPWT 分叉出两条“存在”算法：

## 1. RL-EFE (Reinforcement Learning - Expected Free Energy, RL-EFE)

> 存在是预测世界并选择最利于自己的未来。

Friston 亲领的强化学习-期望自由能路线，继承经典的二元论世界观：

1. 脑内建模型 `p(s,o|π)`
2. rollout 全部未来
3. 算期望自由能 `G(π)`
4. 选 `argmax G`，执行

表面是强化学习，实则是策略梯度与手工奖励的遮羞布。

> “RL-EFE is a beautiful cul-de-sac: Laplace's demon tries to price every tomorrow and is suffocated by its own weight.”

## 2. SOO-OFE (Second-Order Optimization - Observed Free Energy, SOO-OFE)

> 存在是沿着自由能最小化的测地线滑行。

我们自研的“二阶优化-观测自由能”路线，将贝叶斯推断的统计学问题，重构为几何流上的控制理论问题。在此框架下，智能体（模型）是一个由参数 `θ` 定义的确定性刚体，其学习过程是在一个由数据塑造的能量地貌上，沿着能量最小化的测地线进行演化。

- **参数空间**: 一个由黎曼度量张量 `g(θ)` 定义的几何流形。
- **势能 (Potential Energy)**: 由数据拟合误差 `L(D|M)` 提供，是唯一允许数据进入的环节。
- **约束力 (Constraint Force)**: 由模型的内在代数复杂度 `L(M)` 提供，完全由权重矩阵的谱结构等本征属性决定。
- **演化路径**: 同时最小化势能与约束力的测地线。

系统不“选择”动作，而是其内部结构随数据流自然演化，涌现出最高效的信念更新。

## 3. SOO-OFE 的物理约束：确定性重参数化

SOO-OFE 路线的独特之处，在于它对传统贝叶斯推断的哲学性重构。它用代数结构的能量约束，替代了后验分布的高维体积积分，从而解决了传统方法在工程实现上的“结构性缺陷”。

- **常规贝叶斯**: 将模型参数 `θ` 视为一个需要积分掉的随机变量，`p(y|x) = ∫ p(y|x,θ) p(θ) dθ`。不确定性内生于模型，但其高维积分在计算上不可行。
- **确定性重参数化 (我们的方法)**: 将模型 `f(x; θ)` 视为一个完全确定性的物理过程。不确定性被完全外化到马尔科夫毯的边界——即随机的输入 `x` 和随机的输出采样 `y`。

这类似于变分自编码器 (VAE) 中的重参数化技巧 `z = μ + σ·ε`，它将随机性从潜变量 `z` 转移到了一个外部的、固定的噪声源 `ε`。我们的哲学，就是将整个模型的不确定性，通过这种方式完全隔离在系统之外。

这一看似微小的哲学分野，对 SOO-OFE 的实现施加了**不可妥协的约束**：

**对模型复杂度 `L(M)` 的度量，必须是系统的本征属性（Intrinsic Property），形式上是一个纯粹的、数据无关的代数函数，构建于算子理论而非统计学之上。**

这一约束澄清了两种核心工具的界限：

- **Fisher 信息矩阵 (FIM)**: 一个依赖数据的**统计量**，用于在能量地貌上找到降低“势能” `L(D|M)` 的最速下降方向（即自然梯度）。
- **黎曼度量张量**: 一个数据无关的**几何量**，用于定义“约束力” `L(M)`，其形式应为权重矩阵的**算子谱**（如奇异值分布的熵、Schatten p-范数等）。

任何试图用依赖数据的量（如 Hessian 或经验 FIM）来度量 `L(M)` 的行为，都将从外部引入统计噪声，破坏系统内部的确定性，导致理论上的自相矛盾。

因此，SOO-OFE 的探索方向必然地、唯一地指向了对参数矩阵**代数谱结构**的优化。
